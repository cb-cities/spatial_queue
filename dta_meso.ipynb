{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time \n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from ctypes import *\n",
    "import scipy.io as sio\n",
    "from shapely.wkt import loads\n",
    "import scipy.sparse as ssparse\n",
    "from operator import itemgetter\n",
    "from multiprocessing import Pool, Process, Queue\n",
    "from pympler.asizeof import asizeof\n",
    "\n",
    "absolute_path = '/home/bingyu/Documents/spatial_queue'\n",
    "sys.path.insert(0, absolute_path+'/../')\n",
    "from sp import interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(counterflow=False, closure=False, network_file_edges=None, network_file_nodes=None, simulation_outputs=None, scen_nm=''):\n",
    "\n",
    "    links_df0 = pd.read_csv(absolute_path+network_file_edges)\n",
    "    \n",
    "    links_df0['lanes'] = np.where(links_df0['type'].isin(['residential', 'secondary', 'secondary_link', 'tertiary', 'tertiary_link']), 1, links_df0['lanes'])\n",
    "    links_df0['maxmph'] = np.where(links_df0['type'].isin(['residential', 'secondary', 'secondary_link', 'tertiary', 'tertiary_link']), 25, links_df0['maxmph'])\n",
    "    \n",
    "    if counterflow == True:\n",
    "#         counterflow_roads = ['euclid_ave', 'spruce_ave', 'grizzly_peak_blvd']\n",
    "        counterflow_roads = ['marin_ave', 'marin_ave_2', 'laloma_ave', 'college_ave']\n",
    "        downhill_roads = []\n",
    "        uphill_roads = []\n",
    "        for cfr in counterflow_roads:\n",
    "            cfr_df = pd.read_csv(absolute_path+'/../network/outputs/{}_dir.csv'.format(cfr))\n",
    "            downhill_roads += cfr_df.loc[cfr_df['downhills']==1, 'edge_id_igraph'].values.tolist()\n",
    "            uphill_roads = cfr_df.loc[cfr_df['downhills']==0, 'edge_id_igraph'].values.tolist()\n",
    "        links_df0['lanes'] = np.where(links_df0['edge_id_igraph'].isin(downhill_roads), 2, links_df0['lanes'])\n",
    "        links_df0['lanes'] = np.where(links_df0['edge_id_igraph'].isin(uphill_roads), 0, links_df0['lanes'])\n",
    "        links_df0['maxmph'] = np.where(links_df0['edge_id_igraph'].isin(uphill_roads), 0.01, links_df0['maxmph'])\n",
    "    \n",
    "    if closure == True:\n",
    "        closure_roads = ['neal_road', 'clark_road', 'pentz_road']\n",
    "        closure_road_ids = []\n",
    "        for clr in closure_roads:\n",
    "            clr_df = pd.read_csv(absolute_path+'/../network/data/butte/osm_edges_{}.csv'.format(clr))\n",
    "            closure_road_ids += clr_df['edge_id_igraph'].values.tolist()\n",
    "        links_df0['lanes'] = np.where(links_df0['edge_id_igraph'].isin(closure_road_ids), 0, links_df0['lanes'])\n",
    "        links_df0['maxmph'] = np.where(links_df0['edge_id_igraph'].isin(closure_road_ids), 0.01, links_df0['maxmph'])\n",
    "\n",
    "    links_df0['fft'] = links_df0['length']/links_df0['maxmph']*2.237\n",
    "    links_df0['capacity'] = 2000*links_df0['lanes']\n",
    "    links_df0['store_cap'] = links_df0['length']*links_df0['lanes']/8 \n",
    "    links_df0['store_cap'] = np.where(links_df0['store_cap']<1, 1, links_df0['store_cap'])\n",
    "    links_df0['stype'] = 'real'\n",
    "    links_df0 = links_df0[['edge_id_igraph', 'start_igraph', 'end_igraph', 'stype', 'lanes', 'capacity', 'fft', 'length', 'store_cap', 'geometry']]\n",
    "\n",
    "    nodes_df0 = pd.read_csv(absolute_path+network_file_nodes)\n",
    "    nodes_df0['node_id_sp'] = nodes_df0['node_id_igraph'] + 1\n",
    "\n",
    "    ### Convert to mtx\n",
    "    wgh = links_df0['fft']\n",
    "    row = links_df0['start_igraph']\n",
    "    col = links_df0['end_igraph']\n",
    "    assert max(np.max(row)+1, np.max(col)+1) == nodes_df0.shape[0], 'nodes and links dimension do not match, row {}, col {}, nodes {}'.format(np.max(row), np.max(col), nodes_df0.shape[0])\n",
    "    g_coo = ssparse.coo_matrix((wgh, (row, col)), shape=(nodes_df0.shape[0], nodes_df0.shape[0]))\n",
    "    print(g_coo.shape, len(g_coo.data))\n",
    "    sio.mmwrite(absolute_path+simulation_outputs+'/network_sparse.mtx', g_coo)\n",
    "    # g_coo = sio.mmread(absolute_path+'/outputs/network_sparse.mtx'.format(folder))\n",
    "\n",
    "    g = interface.readgraph(bytes(absolute_path+simulation_outputs+'/network_sparse.mtx', encoding='utf-8'))\n",
    "\n",
    "    return g, links_df0, nodes_df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demand(nodes_df0, phased_flag = False, demand_file=None):\n",
    "    \n",
    "    od = pd.read_csv(absolute_path + demand_file)\n",
    "    od['agent_id'] = range(od.shape[0])\n",
    "    od = pd.merge(od, nodes_df0[['node_id_igraph', 'node_osmid']], how='left', left_on='origin_osmid', right_on='node_osmid')\n",
    "    od['o_sp'] = od['node_id_igraph'] + 1\n",
    "    od = pd.merge(od[['agent_id', 'o_sp', 'destin_osmid', 'time']], nodes_df0[['node_id_igraph', 'node_osmid']], how='left', left_on='destin_osmid', right_on='node_osmid')\n",
    "    od['d_sp'] = od['node_id_igraph'] + 1\n",
    "    if phased_flag == False:\n",
    "        od['time'] = 0\n",
    "    od = od[['agent_id', 'o_sp', 'd_sp', 'time']]\n",
    "    print(od.shape)\n",
    "    print(od.head())\n",
    "\n",
    "    return od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sp(agent):\n",
    "    \n",
    "    ### Find shortest path for each unique origin --> one destination\n",
    "    agent_id = int(od['agent_id'].iloc[agent])\n",
    "    origin_ID = int(od['o_sp'].iloc[agent])\n",
    "    destin_ID = int(od['d_sp'].iloc[agent])\n",
    "    depart_time = int(od['time'].iloc[agent])\n",
    "\n",
    "    sp = g.dijkstra(origin_ID, destin_ID)\n",
    "\n",
    "    sp_dist = sp.distance(destin_ID) ### agent believed travel time with imperfect information\n",
    "    if sp_dist > 10e7:\n",
    "        sp_edges = []\n",
    "        results = {'agent_id': agent_id, 'o_sp': origin_ID, 'd_sp': destin_ID, 'd_tm': depart_time, 'route_igraph': sp_edges}\n",
    "        return results, 'n_a'\n",
    "    else:\n",
    "        sp_route = sp.route(destin_ID)\n",
    "        path = [('vn{}'.format(origin_ID-1), origin_ID-1)] + [(start_sp-1, end_sp-1) for (start_sp, end_sp) in sp_route]\n",
    "        results = {'agent_id': agent_id, 'o_sp': origin_ID, 'd_sp': destin_ID, 'd_tm': depart_time, 'route_igraph': path}\n",
    "        ### [(edge[0], edge[1]) for edge in sp_route]: agent's choice of route\n",
    "        return results, 'a' ### 'a' means arrival\n",
    "    \n",
    "def reduce_edge_flow(agent_info_routes):\n",
    "    ### Reduce (count the total traffic flow per edge) with pandas groupby\n",
    "\n",
    "    flat_L = [(e[0], e[1]) for r in agent_info_routes for e in r['route_igraph'] if len(r['route_igraph'])>0]\n",
    "    df_L = pd.DataFrame(flat_L, columns=['start_igraph', 'end_igraph'])\n",
    "    df_L_flow = df_L.groupby(['start_igraph', 'end_igraph']).size().reset_index().rename(columns={0: 'vol'})\n",
    "    \n",
    "    return df_L_flow\n",
    "\n",
    "def route(od, links_df0, counterflow=False, scen_nm='', simulation_outputs=None):\n",
    "\n",
    "    ### Build a pool\n",
    "    process_count = 1\n",
    "    pool = Pool(processes=process_count)\n",
    "\n",
    "    ### Find shortest pathes\n",
    "    unique_origin = len(od)\n",
    "    t_odsp_0 = time.time()\n",
    "    print('unique_origin', unique_origin)\n",
    "\n",
    "    res = pool.imap_unordered(map_sp, range(unique_origin))\n",
    "\n",
    "    ### Close the pool\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    t_odsp_1 = time.time()\n",
    "\n",
    "    agent_info_routes, destination_counts = zip(*res)\n",
    "    edge_volume = reduce_edge_flow(agent_info_routes)\n",
    "    # print(edge_volume.describe())\n",
    "    edge_volume = pd.merge(links_df0[['edge_id_igraph', 'start_igraph', 'end_igraph', 'capacity', 'geometry']], edge_volume, how='left', on=['start_igraph', 'end_igraph'])\n",
    "    edge_volume = edge_volume.fillna(value={'vol': 0})\n",
    "    ### voc\n",
    "    edge_volume['voc'] = edge_volume['vol']/edge_volume['capacity']\n",
    "    edge_volume = edge_volume.sort_values(by='voc', ascending=False)\n",
    "    edge_volume[['edge_id_igraph', 'start_igraph', 'end_igraph', 'geometry', 'vol', 'voc']].to_csv(absolute_path+simulation_outputs+'/initial_route_volume_a{}_{}.csv'.format(len(agent_info_routes), scen_nm), index=False)\n",
    "\n",
    "    cannot_arrive = np.sum([1 for i in destination_counts if i=='n_a'])\n",
    "    print('{} out of {} cannot arrive.'.format(cannot_arrive, unique_origin))\n",
    "\n",
    "    agent_info = {a['agent_id']: {'o_sp': a['o_sp'], 'd_sp': a['d_sp'], 'd_tm': a['d_tm'], 'route_igraph': a['route_igraph']} for a in agent_info_routes if len(a['route_igraph'])>0}\n",
    "    print('number of agents for network loading {}'.format(len(agent_info)))\n",
    "\n",
    "    return agent_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def virtual_nodes_links(links_df0, nodes_df0):\n",
    "\n",
    "    virtual_nodes_df = nodes_df0.copy()\n",
    "    virtual_nodes_df['node_id_igraph'] = virtual_nodes_df['node_id_igraph'].apply(lambda x: 'vn{}'.format(x))\n",
    "    virtual_nodes_df['node_id_sp'] = virtual_nodes_df['node_id_sp'].apply(lambda x: 'vn{}_sp'.format(x))\n",
    "    virtual_nodes_df['lon'] = virtual_nodes_df['lon'] + 0.001\n",
    "    virtual_nodes_df['lat'] = virtual_nodes_df['lat'] + 0.001\n",
    "    nodes_df = pd.concat([nodes_df0, virtual_nodes_df], sort=False, ignore_index=True)\n",
    "\n",
    "    virtual_links_dict = {'edge_id_igraph':[], 'start_igraph':[], 'end_igraph':[], 'stype': [], 'lanes': [], 'capacity':[], 'fft':[], 'length':[], 'store_cap':[], 'geometry':[]}\n",
    "    for node in nodes_df0.itertuples():\n",
    "        node_id = getattr(node, 'node_id_igraph')\n",
    "        node_lon = getattr(node, 'lon')\n",
    "        node_lat = getattr(node, 'lat')\n",
    "\n",
    "        virtual_links_dict['edge_id_igraph'].append('n{}_vl'.format(node_id))\n",
    "        virtual_links_dict['start_igraph'].append('vn{}'.format(node_id))\n",
    "        virtual_links_dict['end_igraph'].append(node_id)\n",
    "        virtual_links_dict['stype'].append('v')\n",
    "        virtual_links_dict['lanes'].append(100)\n",
    "        virtual_links_dict['capacity'].append(100000)\n",
    "        virtual_links_dict['fft'].append(0)\n",
    "        virtual_links_dict['length'].append(0)\n",
    "        virtual_links_dict['store_cap'].append(100000)\n",
    "        virtual_links_dict['geometry'].append('LINESTRING({} {}, {} {})'.format(node_lon+0.001, node_lat+0.001, node_lon, node_lat))\n",
    "    virtual_links_df = pd.DataFrame(virtual_links_dict)\n",
    "    links_df = pd.concat([links_df0, virtual_links_df], sort=False, ignore_index=True)\n",
    "\n",
    "    return links_df, nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sending_receiving_0(t, t_scale, links_dict=None, links_attr_dict=None):\n",
    "\n",
    "    new_links_dict = {}\n",
    "    for l_id, l_traf in links_dict.items():\n",
    "        l_traf_run_new = []\n",
    "        l_traf_queue_new = l_traf['queue']\n",
    "        for [agent, t_enter] in l_traf['run']:\n",
    "            if t_enter < t*t_scale - links_attr_dict[l_id]['fft']:\n",
    "                l_traf_queue_new.append([agent, t_enter])\n",
    "            else:\n",
    "                l_traf_run_new.append([agent, t_enter])\n",
    "        l_traf_sending_new = links_attr_dict[l_id]['ou_c']/3600*t_scale\n",
    "        l_traf_receiving_new = links_attr_dict[l_id]['in_c']/3600*t_scale\n",
    "        l_traf_store_cap_remain = links_attr_dict[l_id]['st_c'] - len(l_traf_run_new) - len(l_traf_queue_new) ###? storage cap does not change with time slice size, but sending and receiving cap change with time slice size\n",
    "        new_links_dict[l_id] = {'run': l_traf_run_new, 'queue': l_traf_queue_new, 'send': l_traf_sending_new, 'receive': l_traf_receiving_new, 'st_remain': l_traf_store_cap_remain}\n",
    "        \n",
    "    return new_links_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodal_transfer(t=0, t_scale=1, nodes_dict=None, links_dict=None, links_attr_dict=None, links_trav_time_dict=0, node2edge=None, agent_info=None, reroute_flag=False):\n",
    "\n",
    "    arrival_list = []\n",
    "    move = 0\n",
    "\n",
    "    for n, in_out in nodes_dict.items():\n",
    "\n",
    "        in_links = in_out['in_links'].keys()\n",
    "        out_links = in_out['out_links']\n",
    "        x_mid = in_out['lon']\n",
    "        y_mid = in_out['lat']\n",
    "\n",
    "        in_links = [l for l in in_links if len(links_dict[l]['queue'])>0]\n",
    "        if len(in_links) == 0:\n",
    "            continue\n",
    "\n",
    "        go_link = random.choice(in_links)\n",
    "        x_start = nodes_dict[links_attr_dict[go_link]['s_i']]['lon']\n",
    "        y_start = nodes_dict[links_attr_dict[go_link]['s_i']]['lat']\n",
    "        in_vec = (x_mid-x_start, y_mid-y_start)\n",
    "        go_vehs = []\n",
    "        left_turn_vehs = False\n",
    "        incoming_lanes = int(np.floor(links_attr_dict[go_link]['ln']))\n",
    "        incoming_vehs = len(links_dict[go_link]['queue'])\n",
    "        for ln in range(min(incoming_lanes, incoming_vehs)):\n",
    "            [agent_id, link_enter_time] = links_dict[go_link]['queue'][ln]\n",
    "            try:\n",
    "                agent_next_node = [end for (start, end) in agent_info[agent_id]['route_igraph'] if start == n][0]\n",
    "            except IndexError:\n",
    "                go_vehs.append([agent_id, None, go_link, None, link_enter_time])\n",
    "                left_turn_vehs = False or left_turn_vehs\n",
    "                continue\n",
    "\n",
    "            ol = node2edge[(n, agent_next_node)]\n",
    "            go_vehs.append([agent_id, agent_next_node, go_link, ol, link_enter_time])\n",
    "            if links_attr_dict[go_link]['ty']=='v': ### virtual enter\n",
    "                left_turn_vehs = False or left_turn_vehs\n",
    "            else:\n",
    "                x_end = nodes_dict[agent_next_node]['lon']\n",
    "                y_end = nodes_dict[agent_next_node]['lat']\n",
    "                out_vec = (x_end-x_mid, y_end-y_mid)\n",
    "                dot = (in_vec[0]*out_vec[0] + in_vec[1]*out_vec[1])\n",
    "                det = (in_vec[0]*out_vec[1] - in_vec[1]*out_vec[0])\n",
    "                agent_dir = np.arctan2(det, dot)*180/np.pi \n",
    "                if agent_dir < -45:\n",
    "                    left_turn_vehs = True or left_turn_vehs\n",
    "        \n",
    "        op_go_vehs = []\n",
    "        if (not left_turn_vehs) and (links_attr_dict[go_link]['ty']=='real'):\n",
    "            op_go_link = nodes_dict[n]['in_links'][go_link]\n",
    "            if op_go_link == None:\n",
    "                pass\n",
    "            else:\n",
    "                x_start = nodes_dict[links_attr_dict[go_link]['s_i']]['lon']\n",
    "                y_start = nodes_dict[links_attr_dict[go_link]['s_i']]['lat']\n",
    "                in_vec = (x_mid-x_start, y_mid-y_start)\n",
    "                op_incoming_lanes = int(np.floor(links_attr_dict[op_go_link]['ln']))\n",
    "                op_incoming_vehs = len(links_dict[op_go_link]['queue'])\n",
    "                for ln in range(min(op_incoming_lanes, op_incoming_vehs)):\n",
    "                    [agent_id, link_enter_time] = links_dict[op_go_link]['queue'][ln]\n",
    "                    try:\n",
    "                        agent_next_node = [end for (start, end) in agent_info[agent_id]['route_igraph'] if start == n][0]\n",
    "                    except IndexError:\n",
    "                        op_go_vehs.append([agent_id, None, op_go_link, None, link_enter_time])\n",
    "                        continue\n",
    "                    ol = node2edge[(n, agent_next_node)]\n",
    "                    x_end = nodes_dict[agent_next_node]['lon']\n",
    "                    y_end = nodes_dict[agent_next_node]['lat']\n",
    "                    out_vec = (x_end-x_mid, y_end-y_mid)\n",
    "                    dot = (in_vec[0]*out_vec[0] + in_vec[1]*out_vec[1])\n",
    "                    det = (in_vec[0]*out_vec[1] - in_vec[1]*out_vec[0])\n",
    "                    agent_dir = np.arctan2(det, dot)*180/np.pi \n",
    "                    if agent_dir > 45:\n",
    "                        op_go_vehs.append([agent_id, agent_next_node, op_go_link, ol, link_enter_time])\n",
    "                    elif agent_dir > -45:\n",
    "                        op_go_vehs.append([agent_id, agent_next_node, op_go_link, ol, link_enter_time])\n",
    "                    else:\n",
    "                        pass ### no left turn allowed for opposite lane \"bonus movement\"\n",
    "                \n",
    "        for go_vehs_list in [go_vehs, op_go_vehs]:\n",
    "            for [agent_id, next_node, il, ol, link_enter_time] in go_vehs_list:\n",
    "\n",
    "                ### Agent reaching destination\n",
    "                if (next_node is None) and (n == agent_info[agent_id]['d_sp']-1):\n",
    "                    #print('arrive')\n",
    "                    arrival_list.append([agent_id, t])\n",
    "                    links_dict[go_link]['queue'] = [v for v in links_dict[go_link]['queue'] if v[0]!=agent_id]\n",
    "                    links_dict[go_link]['send'] = max(0, links_dict[go_link]['send']-1)\n",
    "                    try:\n",
    "                        links_trav_time_dict[go_link].append(t*t_scale-link_enter_time)\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                    continue\n",
    "                \n",
    "                ### no storage capacity downstream\n",
    "                if links_dict[ol]['st_remain'] < 1:\n",
    "                    pass ### no blocking, as # veh = # lanes\n",
    "                ### inlink-sending, outlink-receiving both permits\n",
    "                elif (links_dict[il]['send'] >= 1) & (links_dict[ol]['receive'] >= 1):\n",
    "                    move += 1\n",
    "                    links_dict[il]['queue'] = [v for v in links_dict[il]['queue'] if v[0]!=agent_id]\n",
    "                    links_dict[il]['send'] -= 1 ### guaranted larger than 0\n",
    "                    links_dict[ol]['run'].append((agent_id, t*t_scale))\n",
    "                    links_dict[ol]['receive'] -= 1 ### guaranted larger than 0\n",
    "                    if ol==24586: print('second', links_dict[ol])\n",
    "                    try:\n",
    "                        links_trav_time_dict[il].append(t*t_scale-link_enter_time)\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                else: ### either inlink-sending or outlink-receiving or both exhaust\n",
    "                    control_cap = min(links_dict[il]['send'], links_dict[ol]['receive'])\n",
    "                    toss_coin = random.choices([0,1], weights=[1-control_cap, control_cap], k=1)\n",
    "                    if toss_coin[0]:\n",
    "                        move += 1\n",
    "                        links_dict[il]['queue'] = [v for v in links_dict[il]['queue'] if v[0]!=agent_id]\n",
    "                        links_dict[il]['send'] = max(0, links_dict[il]['send']-1)\n",
    "                        links_dict[ol]['run'].append((agent_id, t*t_scale))\n",
    "                        links_dict[ol]['receive'] = max(0, links_dict[ol]['receive']-1)\n",
    "                        try:\n",
    "                            links_trav_time_dict[il].append(t*t_scale-link_enter_time)\n",
    "                        except KeyError:\n",
    "                            pass\n",
    "                    else:\n",
    "                        pass\n",
    "    \n",
    "    return links_dict, links_trav_time_dict, arrival_list, move, agent_info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trips(t, t_scale, agent_info, links_dict, node2edge):\n",
    "\n",
    "    for a, info in agent_info.items():\n",
    "        if info['d_tm'] == t:\n",
    "            initial_edge = node2edge[info['route_igraph'][0]]\n",
    "            links_dict[initial_edge]['run'].append([a, t*t_scale])\n",
    "        \n",
    "    return links_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256) 605\n",
      "(500, 4)\n",
      "   agent_id  o_sp  d_sp  time\n",
      "0         0   177   156     0\n",
      "1         1   179   187     0\n",
      "2         2   120   187     0\n",
      "3         3    54   187     0\n",
      "4         4   194   156     0\n",
      "unique_origin 500\n",
      "0.0 out of 500 cannot arrive.\n",
      "number of agents for network loading 500\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "global g\n",
    "global od\n",
    "\n",
    "reroute_flag = False\n",
    "counterflow_flag = False\n",
    "closure_flag = False\n",
    "phased_flag = False\n",
    "scen_nm = 'not_phased'\n",
    "network_file_edges = '/projects/bolinas_stinson_beach/network_inputs/osm_edges.csv'\n",
    "network_file_nodes = '/projects/bolinas_stinson_beach/network_inputs/osm_nodes.csv'\n",
    "demand_file = '/projects/bolinas_stinson_beach/demand_inputs/stinson_beach_od_500.csv'\n",
    "simulation_outputs = '/projects/bolinas_stinson_beach/simulation_outputs'\n",
    "\n",
    "t_scale = 1\n",
    "\n",
    "g, links_df0, nodes_df0 = network(\n",
    "    counterflow=counterflow_flag, \n",
    "    closure=closure_flag, \n",
    "    network_file_edges = network_file_edges,\n",
    "    network_file_nodes = network_file_nodes,\n",
    "    simulation_outputs = simulation_outputs,\n",
    "    scen_nm = scen_nm)\n",
    "od = demand(nodes_df0, \n",
    "            phased_flag = phased_flag,\n",
    "            demand_file = demand_file)\n",
    "agent_info = route(od, links_df0, \n",
    "                   counterflow=counterflow_flag, \n",
    "                   simulation_outputs = simulation_outputs,\n",
    "                   scen_nm = scen_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(861, 10) (512, 6) (605, 10) (256, 6)\n"
     ]
    }
   ],
   "source": [
    "links_df, nodes_df = virtual_nodes_links(links_df0, nodes_df0)\n",
    "print(links_df.shape, nodes_df.shape, links_df0.shape, nodes_df0.shape)\n",
    "node2edge = {(getattr(e, 'start_igraph'), getattr(e, 'end_igraph')): getattr(e, 'edge_id_igraph') for e in links_df.itertuples()}\n",
    "links_attr_dict = {getattr(e, 'edge_id_igraph'): {'fft': getattr(e, 'fft'), 'len': getattr(e, 'length'), 'ty': getattr(e, 'stype'), 'ln': getattr(e, 'lanes'), 's_i': getattr(e, 'start_igraph'), 'e_i': getattr(e, 'end_igraph'), 'geom': getattr(e, 'geometry'), 'in_c': getattr(e, 'capacity'), 'ou_c': getattr(e, 'capacity'), 'st_c': getattr(e, 'store_cap')} for e in links_df.itertuples()}\n",
    "# ### signal at entrance to chico\n",
    "# links_attr_dict[21044]['ou_c'] /= 2\n",
    "links_dict = {e: {'run': [], 'queue': []} for e in links_df['edge_id_igraph'].values.tolist()}\n",
    "links_trav_time_dict = {e: [] for e in links_df.loc[links_df['stype']=='real', 'edge_id_igraph'].values.tolist()}\n",
    "\n",
    "nodes_dict = {getattr(n, 'node_id_igraph'): {'in_links': {}, 'out_links': [], 'lon': getattr(n, 'lon'), 'lat': getattr(n, 'lat')} for n in nodes_df.itertuples()}\n",
    "for l in links_df.itertuples():\n",
    "    nodes_dict[getattr(l, 'start_igraph')]['out_links'].append(getattr(l, 'edge_id_igraph'))\n",
    "    nodes_dict[getattr(l, 'end_igraph')]['in_links'][getattr(l, 'edge_id_igraph')] = None\n",
    "for n, in_out in nodes_dict.items():\n",
    "    x_mid = in_out['lon']\n",
    "    y_mid = in_out['lat']\n",
    "    for il in in_out['in_links'].keys():\n",
    "        x_start = nodes_dict[links_attr_dict[il]['s_i']]['lon']\n",
    "        y_start = nodes_dict[links_attr_dict[il]['s_i']]['lat']\n",
    "        in_vec = (x_mid-x_start, y_mid-y_start)\n",
    "        sa_ol = None\n",
    "        ol_dir = 180\n",
    "        for ol in in_out['out_links']:\n",
    "            x_end = nodes_dict[links_attr_dict[ol]['e_i']]['lon']\n",
    "            y_end = nodes_dict[links_attr_dict[ol]['e_i']]['lat']\n",
    "            out_vec = (x_end-x_mid, y_end-y_mid)\n",
    "            dot = (in_vec[0]*out_vec[0] + in_vec[1]*out_vec[1])\n",
    "            det = (in_vec[0]*out_vec[1] - in_vec[1]*out_vec[0])\n",
    "            new_ol_dir = np.arctan2(det, dot)*180/np.pi\n",
    "            if abs(new_ol_dir)<ol_dir:\n",
    "                sa_ol = ol\n",
    "                ol_dir = new_ol_dir\n",
    "        if (abs(ol_dir)<=45) and links_attr_dict[il]['ty']=='real':\n",
    "            nodes_dict[n]['in_links'][il] = sa_ol\n",
    "\n",
    "total_arrival_count = 0\n",
    "total_arrival_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 71]\n",
      "[200, 0, 9, 203, 35, 28]\n",
      "[400, 30, 6, 44, 12, 21]\n",
      "[600, 122, 3, 0, 0, 7]\n",
      "[800, 263, 0, 0, 0, 5]\n",
      "[1000, 410, 0, 0, 0, 2]\n",
      "[1200, 490, 0, 0, 0, 1]\n",
      "[1400, 500, 0, 0, 0, 0]\n",
      "[1600, 500, 0, 0, 0, 0]\n",
      "[1800, 500, 0, 0, 0, 0]\n",
      "[2000, 500, 0, 0, 0, 0]\n",
      "[2200, 500, 0, 0, 0, 0]\n",
      "[2400, 500, 0, 0, 0, 0]\n",
      "[2600, 500, 0, 0, 0, 0]\n",
      "[2800, 500, 0, 0, 0, 0]\n",
      "[3000, 500, 0, 0, 0, 0]\n",
      "[3200, 500, 0, 0, 0, 0]\n",
      "[3400, 500, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "t_s = 0\n",
    "t_e = 3600\n",
    "for t in range(t_s, t_e):\n",
    "    links_dict = load_trips(t, t_scale, agent_info, links_dict, node2edge)\n",
    "    links_dict = sending_receiving_0(t, t_scale, links_dict=links_dict, links_attr_dict=links_attr_dict)\n",
    "#     veh_loc = []\n",
    "#     for l_id, l in links_dict.items():\n",
    "#         if links_attr_dict[l_id]['ty'] == 'v':\n",
    "#             continue\n",
    "#         l_len = links_attr_dict[l_id]['len']\n",
    "#         l_ln = links_attr_dict[l_id]['ln']\n",
    "#         l_fft = links_attr_dict[l_id]['fft']\n",
    "#         l_geom = loads(links_attr_dict[l_id]['geom'])\n",
    "#         q_v_loc = l_len\n",
    "#         q_v_loc_count = 0\n",
    "#         run_veh = sorted(l['run'],key=itemgetter(1))\n",
    "#         queue_veh = sorted(l['queue'],key=itemgetter(1))\n",
    "#         for q_v in queue_veh:\n",
    "#             q_v_loc = max(min(q_v_loc*(1), l_len), 0)\n",
    "#             q_v_coord = l_geom.interpolate(q_v_loc/l_len, normalized=True)\n",
    "#             veh_loc.append([t, l_id, q_v[0], 'q', q_v_coord.x, q_v_coord.y])\n",
    "#             q_v_loc_count += 1\n",
    "#             if q_v_loc_count == l_ln:\n",
    "#                 q_v_loc -= 8\n",
    "#                 q_v_loc_count = 0\n",
    "#         queue_loc = current_loc\n",
    "#         for r_v in run_veh:\n",
    "#             if l_len*(t-r_v[1])/l_fft>queue_loc:\n",
    "#                 r_v_loc = queue_loc\n",
    "#                 q_v_loc_count += 1\n",
    "#                 if q_v_loc_count == l_ln:\n",
    "#                     q_v_loc -= 8\n",
    "#                     q_v_loc_count = 0\n",
    "#             else:\n",
    "#                 r_v_loc = l_len*(t-r_v[1])/l_fft\n",
    "#             r_v_loc = max(min(r_v_loc*(1), l_len), 0)\n",
    "#             r_v_coord = l_geom.interpolate(r_v_loc/l_len, normalized=True)\n",
    "#             veh_loc.append([t, l_id, r_v[0], 'r', r_v_coord.x, r_v_coord.y])\n",
    "#     pd.DataFrame(veh_loc, columns=['t_sec', 'l_id', 'v_id', 'status', 'lon', 'lat']).to_csv('outputs/veh_loc/veh_loc_{}s.csv'.format(t), index=False)\n",
    "        \n",
    "        \n",
    "    links_dict, links_trav_time_dict, arrival_list, move, agent_info = nodal_transfer(t=t, t_scale=t_scale, nodes_dict=nodes_dict, links_dict=links_dict, links_attr_dict=links_attr_dict, links_trav_time_dict=links_trav_time_dict, node2edge=node2edge, agent_info=agent_info, reroute_flag=reroute_flag)\n",
    "    total_arrival_count += len(arrival_list)\n",
    "    queue_veh = sum([len(l['queue']) for l in links_dict.values()])\n",
    "    queue_link = len([l for l in links_dict.values() if len(l['queue'])>0])\n",
    "    run_link = len([l for l in links_dict.values() if len(l['run'])>0])\n",
    "    total_arrival_list.append([t, total_arrival_count, move, queue_veh, queue_link, run_link])\n",
    "\n",
    "    if t%200==0:\n",
    "        print(total_arrival_list[-1])\n",
    "        ### reset the average travel time\n",
    "        links_trav_time_dict = {getattr(e, 'edge_id_igraph'): [] for e in links_df.itertuples() if getattr(e, 'stype')=='real'}\n",
    "        pd.DataFrame([[l, len(v['run']), len(v['queue']), links_attr_dict[l]['geom']] for l, v in links_dict.items()], columns=['edge_id_igraph', 'run', 'queue', 'geom']).to_csv(absolute_path+simulation_outputs+'/run_queue/run_queue_{}_{}s.csv'.format(scen_nm, t), index=False)\n",
    "        \n",
    "pd.DataFrame(total_arrival_list, columns=['t_sec', 'tot_arr', 'move', 'q_veh', 'q_l', 'r_l']).to_csv(absolute_path+simulation_outputs+'/arrival_counts/arrival_counts_{}_{}s_{}s.csv'.format(scen_nm, t_s, t_e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:geo] *",
   "language": "python",
   "name": "conda-env-geo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
