{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import time \n",
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from ctypes import *\n",
    "import scipy.io as sio\n",
    "from shapely.wkt import loads\n",
    "import scipy.sparse as ssparse\n",
    "from operator import itemgetter\n",
    "from multiprocessing import Pool, Process, Queue\n",
    "from pympler.asizeof import asizeof\n",
    "\n",
    "absolute_path = '/home/bingyu/Documents/spatial_queue'\n",
    "sys.path.insert(0, absolute_path+'/../')\n",
    "from sp import interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network(counterflow=False, closure=False, network_file_edges=None, network_file_nodes=None, simulation_outputs=None, scen_nm=''):\n",
    "\n",
    "    links_df0 = pd.read_csv(absolute_path+network_file_edges)\n",
    "    \n",
    "    links_df0['lanes'] = np.where(links_df0['type'].isin(['residential', 'secondary', 'secondary_link', 'tertiary', 'tertiary_link', 'unclassified']), 1, links_df0['lanes'])\n",
    "    links_df0['maxmph'] = np.where(links_df0['type'].isin(['residential', 'secondary', 'secondary_link', 'tertiary', 'tertiary_link', 'unclassified']), 25, links_df0['maxmph'])\n",
    "\n",
    "    links_df0['lanes'] = np.where(links_df0['type'].isin(['primary', 'primary_link']), 1, links_df0['lanes'])\n",
    "    links_df0['maxmph'] = np.where(links_df0['type'].isin(['primary', 'primary_link']), 55, links_df0['maxmph'])\n",
    "    \n",
    "    if counterflow == True:\n",
    "#         counterflow_roads = ['euclid_ave', 'spruce_ave', 'grizzly_peak_blvd']\n",
    "        counterflow_roads = ['marin_ave', 'marin_ave_2', 'laloma_ave', 'college_ave']\n",
    "        downhill_roads = []\n",
    "        uphill_roads = []\n",
    "        for cfr in counterflow_roads:\n",
    "            cfr_df = pd.read_csv(absolute_path+'/../network/outputs/{}_dir.csv'.format(cfr))\n",
    "            downhill_roads += cfr_df.loc[cfr_df['downhills']==1, 'edge_id_igraph'].values.tolist()\n",
    "            uphill_roads = cfr_df.loc[cfr_df['downhills']==0, 'edge_id_igraph'].values.tolist()\n",
    "        links_df0['lanes'] = np.where(links_df0['edge_id_igraph'].isin(downhill_roads), 2, links_df0['lanes'])\n",
    "        links_df0['lanes'] = np.where(links_df0['edge_id_igraph'].isin(uphill_roads), 0, links_df0['lanes'])\n",
    "        links_df0['maxmph'] = np.where(links_df0['edge_id_igraph'].isin(uphill_roads), 0.01, links_df0['maxmph'])\n",
    "    \n",
    "    if closure == True:\n",
    "        closure_roads = ['neal_road', 'clark_road', 'pentz_road']\n",
    "        closure_road_ids = []\n",
    "        for clr in closure_roads:\n",
    "            clr_df = pd.read_csv(absolute_path+'/../network/data/butte/osm_edges_{}.csv'.format(clr))\n",
    "            closure_road_ids += clr_df['edge_id_igraph'].values.tolist()\n",
    "        links_df0['lanes'] = np.where(links_df0['edge_id_igraph'].isin(closure_road_ids), 0, links_df0['lanes'])\n",
    "        links_df0['maxmph'] = np.where(links_df0['edge_id_igraph'].isin(closure_road_ids), 0.01, links_df0['maxmph'])\n",
    "\n",
    "    links_df0['fft'] = links_df0['length']/links_df0['maxmph']*2.237\n",
    "    links_df0['capacity'] = 2000*links_df0['lanes']\n",
    "    links_df0['store_cap'] = links_df0['length']*links_df0['lanes']/8 \n",
    "    links_df0['store_cap'] = np.where(links_df0['store_cap']<1, 1, links_df0['store_cap'])\n",
    "    links_df0['stype'] = 'real'\n",
    "    links_df0 = links_df0[['edge_id_igraph', 'start_igraph', 'end_igraph', 'stype', 'lanes', 'capacity', 'maxmph', 'fft', 'length', 'store_cap', 'geometry']]\n",
    "    links_df0.to_csv(absolute_path+simulation_outputs+'/simulation_edges.csv', index=False)\n",
    "\n",
    "    nodes_df0 = pd.read_csv(absolute_path+network_file_nodes)\n",
    "    nodes_df0['node_id_sp'] = nodes_df0['node_id_igraph'] + 1\n",
    "\n",
    "    ### Convert to mtx\n",
    "    wgh = links_df0['fft']\n",
    "    row = links_df0['start_igraph']\n",
    "    col = links_df0['end_igraph']\n",
    "    assert max(np.max(row)+1, np.max(col)+1) == nodes_df0.shape[0], 'nodes and links dimension do not match, row {}, col {}, nodes {}'.format(np.max(row), np.max(col), nodes_df0.shape[0])\n",
    "    g_coo = ssparse.coo_matrix((wgh, (row, col)), shape=(nodes_df0.shape[0], nodes_df0.shape[0]))\n",
    "    print(g_coo.shape, len(g_coo.data))\n",
    "    sio.mmwrite(absolute_path+simulation_outputs+'/network_sparse.mtx', g_coo)\n",
    "    # g_coo = sio.mmread(absolute_path+'/outputs/network_sparse.mtx'.format(folder))\n",
    "\n",
    "    g = interface.readgraph(bytes(absolute_path+simulation_outputs+'/network_sparse.mtx', encoding='utf-8'))\n",
    "\n",
    "    return g, links_df0, nodes_df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demand(nodes_df0, phased_flag = False, demand_files=None):\n",
    "    \n",
    "    if demand_files == None:\n",
    "        o_sp = np.random.randint(low=0, high=np.max(nodes_df0['node_id_igraph']), size = 1000) + 1\n",
    "        d_sp = np.random.randint(low=0, high=np.max(nodes_df0['node_id_igraph']), size = 1000) + 1\n",
    "        agent_id = np.arange(1000)\n",
    "        agent_departure_time = np.random.randint(low=0, high=100, size=1000)\n",
    "        od = pd.DataFrame({'agent_id': agent_id, 'o_sp': o_sp, 'd_sp': d_sp, 'd_tm': agent_departure_time})\n",
    "        od['cls'] = od['o_sp'].apply(lambda x: 'vn{}'.format(x-1)) ### id of the start node of the current link\n",
    "        od['cle'] = od['o_sp'] - 1 ### id of the end node of the current link\n",
    "#         od = pd.DataFrame([[0,3024,14902,0,'vn3023',3023]], columns=['agent_id', 'o_sp', 'd_sp', 'd_tm', 'cls', 'cle'])\n",
    "        return od\n",
    "    \n",
    "    else:\n",
    "        all_od_list = []\n",
    "        for demand_file in demand_files:\n",
    "            od = pd.read_csv(absolute_path + demand_file)\n",
    "            \n",
    "            if 'agent_id' not in od.columns:\n",
    "                od['agent_id'] = np.arange(od.shape[0])\n",
    "                \n",
    "            if phased_flag == False:\n",
    "                od['d_tm'] = 0\n",
    "            else:\n",
    "                od['d_tm'] = np.random.randint(low=0, high=3600*5, size=od.shape[0])\n",
    "            \n",
    "            od = pd.merge(od, nodes_df0[['node_id_igraph', 'node_osmid']], how='left', left_on='origin_osmid', right_on='node_osmid')\n",
    "            od['o_sp'] = od['node_id_igraph'] + 1\n",
    "            od = pd.merge(od[['agent_id', 'o_sp', 'destin_osmid', 'd_tm']], nodes_df0[['node_id_igraph', 'node_osmid']], how='left', left_on='destin_osmid', right_on='node_osmid')\n",
    "            od['d_sp'] = od['node_id_igraph'] + 1\n",
    "            all_od_list.append(od)\n",
    "        all_od = pd.concat(all_od_list, sort=False, ignore_index=True)\n",
    "        all_od['cls'] = all_od['o_sp'].apply(lambda x: 'vn{}'.format(x-1)) ### id of the start node of the current link\n",
    "        all_od['cle'] = all_od['o_sp'] - 1 ### id of the end node of the current link\n",
    "        all_od = all_od[['agent_id', 'o_sp', 'd_sp', 'd_tm', 'cls', 'cle']]\n",
    "        all_od = all_od.sample(frac=1).reset_index(drop=True) ### randomly shuffle rows\n",
    "        print('total numbers of agents from file ', all_od.shape)\n",
    "        all_od = all_od.iloc[0:5000].copy()\n",
    "        \n",
    "    print('total numbers of agents taken ', all_od.shape)\n",
    "    print(all_od.head())\n",
    "        \n",
    "    return all_od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sp(agent_id):\n",
    "    \n",
    "    ### Find shortest path for each unique origin --> one destination\n",
    "    origin_ID = agent_info[agent_id]['o_sp']\n",
    "    destin_ID = agent_info[agent_id]['d_sp']\n",
    "    depart_time = agent_info[agent_id]['d_tm']\n",
    "    current_link_start = agent_info[agent_id]['cls']\n",
    "    current_link_end = agent_info[agent_id]['cle']\n",
    "    \n",
    "    sp = g.dijkstra(current_link_end+1, destin_ID)\n",
    "    sp_dist = sp.distance(destin_ID) ### agent believed travel time with imperfect information\n",
    "    \n",
    "    if sp_dist > 10e7:\n",
    "        sp_edges = []\n",
    "        results = {'agent_id': agent_id, 'route_igraph': sp_edges}\n",
    "        sp.clear()\n",
    "        return results, 'n_a'\n",
    "    else:\n",
    "        sp_route = sp.route(destin_ID)\n",
    "        path = [(current_link_start, current_link_end)] + [(start_sp-1, end_sp-1) for (start_sp, end_sp) in sp_route]\n",
    "        sp.clear()\n",
    "#         print('map', agent_info[0])\n",
    "#         print('map', current_link_end, destin_ID, path)\n",
    "        results = {'agent_id': agent_id, 'cls': current_link_start, 'cle': current_link_end, 'o_sp': origin_ID, 'd_sp': destin_ID, 'd_tm': depart_time, 'route_igraph': path}\n",
    "#         print(results, current_link_start, current_link_end)\n",
    "        ### [(edge[0], edge[1]) for edge in sp_route]: agent's choice of route\n",
    "        return results, 'a' ### 'a' means arrival\n",
    "    \n",
    "def reduce_edge_flow(agent_info_routes):\n",
    "    ### Reduce (count the total traffic flow per edge) with pandas groupby\n",
    "\n",
    "    flat_L = [(e[0], e[1]) for r in agent_info_routes for e in r['route_igraph'] if len(r['route_igraph'])>0]\n",
    "    df_L = pd.DataFrame(flat_L, columns=['start_igraph', 'end_igraph'])\n",
    "    df_L_flow = df_L.groupby(['start_igraph', 'end_igraph']).size().reset_index().rename(columns={0: 'vol'})\n",
    "    \n",
    "    return df_L_flow\n",
    "\n",
    "def route(links_df0, counterflow=False, scen_nm='', simulation_outputs=None):\n",
    "\n",
    "    if len(agent_info) == 0:\n",
    "        return {}\n",
    "    \n",
    "    ### Build a pool\n",
    "    process_count = 10\n",
    "    pool = Pool(processes=process_count)\n",
    "\n",
    "    ### Find shortest pathes\n",
    "    t_odsp_0 = time.time()\n",
    "    res = pool.imap_unordered(map_sp, agent_info.keys())\n",
    "\n",
    "    ### Close the pool\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    t_odsp_1 = time.time()\n",
    "\n",
    "    agent_info_routes, destination_counts = zip(*res)\n",
    "    edge_volume = reduce_edge_flow(agent_info_routes)\n",
    "    # print(edge_volume.describe())\n",
    "    edge_volume = pd.merge(links_df0[['edge_id_igraph', 'start_igraph', 'end_igraph', 'capacity', 'geometry']], edge_volume, how='left', on=['start_igraph', 'end_igraph'])\n",
    "    edge_volume = edge_volume.fillna(value={'vol': 0})\n",
    "    ### voc\n",
    "    edge_volume['voc'] = edge_volume['vol']/edge_volume['capacity']\n",
    "    edge_volume = edge_volume.sort_values(by='voc', ascending=False)\n",
    "#     edge_volume[['edge_id_igraph', 'start_igraph', 'end_igraph', 'geometry', 'vol', 'voc']].to_csv(absolute_path+simulation_outputs+'/initial_route_volume_a{}_{}.csv'.format(len(agent_info_routes), scen_nm), index=False)\n",
    "\n",
    "    cannot_arrive = np.sum([1 for i in destination_counts if i=='n_a'])\n",
    "    # print('{} out of {} cannot arrive.'.format(cannot_arrive, len(agent_info)))\n",
    "#     print('routing takes {} sec'.format(t_odsp_1 - t_odsp_0))\n",
    "\n",
    "    new_agent_info = {a['agent_id']: {'o_sp': a['o_sp'], 'd_sp': a['d_sp'], 'd_tm': a['d_tm'], 'cls': a['cls'], 'cle': a['cle'], 'route_igraph': a['route_igraph']} for a in agent_info_routes if len(a['route_igraph'])>0}\n",
    "    \n",
    "    return new_agent_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_graph(links_attr_dict=None, links_trav_time_dict=None, link_time_lookback_freq=None):\n",
    "    ### Update graph\n",
    "\n",
    "    t_update_0 = time.time()\n",
    "    \n",
    "    new_links_trav_time_dict = {}\n",
    "    avg_links_trav_time = []\n",
    "    for k, v in links_trav_time_dict.items():\n",
    "        recent_v = [(t_rec, dur) for (t_rec, dur) in v if (t-t_rec < link_time_lookback_freq)]\n",
    "        if len(recent_v) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            new_links_trav_time_dict[k] = recent_v\n",
    "            avg_links_trav_time.append((k, np.avg([dur for (_, dur) in recent_v])))\n",
    "\n",
    "    if len(avg_links_trav_time) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        for (link_id, avg_trav_time) in avg_links_trav_time:\n",
    "            g.update_edge(links_attr_dict[link_id]['s_i']+1, links_attr_dict[link_id]['e_i']+1, c_double(avg_trav_time))\n",
    "\n",
    "    t_update_1 = time.time()\n",
    "#     print('updating graph takes {} sec'.format(t_update_1 - t_update_0))\n",
    "\n",
    "    return new_links_trav_time_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def virtual_nodes_links(links_df0, nodes_df0):\n",
    "\n",
    "    virtual_nodes_df = nodes_df0.copy()\n",
    "    virtual_nodes_df['node_id_igraph'] = virtual_nodes_df['node_id_igraph'].apply(lambda x: 'vn{}'.format(x))\n",
    "    virtual_nodes_df['node_id_sp'] = virtual_nodes_df['node_id_sp'].apply(lambda x: 'vn{}_sp'.format(x))\n",
    "    virtual_nodes_df['lon'] = virtual_nodes_df['lon'] + 0.001\n",
    "    virtual_nodes_df['lat'] = virtual_nodes_df['lat'] + 0.001\n",
    "    nodes_df = pd.concat([nodes_df0, virtual_nodes_df], sort=False, ignore_index=True)\n",
    "\n",
    "    virtual_links_dict = {'edge_id_igraph':[], 'start_igraph':[], 'end_igraph':[], 'stype': [], 'lanes': [], 'capacity':[], 'fft':[], 'length':[], 'store_cap':[], 'geometry':[]}\n",
    "    for node in nodes_df0.itertuples():\n",
    "        node_id = getattr(node, 'node_id_igraph')\n",
    "        node_lon = getattr(node, 'lon')\n",
    "        node_lat = getattr(node, 'lat')\n",
    "\n",
    "        virtual_links_dict['edge_id_igraph'].append('n{}_vl'.format(node_id))\n",
    "        virtual_links_dict['start_igraph'].append('vn{}'.format(node_id))\n",
    "        virtual_links_dict['end_igraph'].append(node_id)\n",
    "        virtual_links_dict['stype'].append('v')\n",
    "        virtual_links_dict['lanes'].append(100)\n",
    "        virtual_links_dict['capacity'].append(100000)\n",
    "        virtual_links_dict['fft'].append(0)\n",
    "        virtual_links_dict['length'].append(0)\n",
    "        virtual_links_dict['store_cap'].append(100000)\n",
    "        virtual_links_dict['geometry'].append('LINESTRING({} {}, {} {})'.format(node_lon+0.001, node_lat+0.001, node_lon, node_lat))\n",
    "    virtual_links_df = pd.DataFrame(virtual_links_dict)\n",
    "    links_df = pd.concat([links_df0, virtual_links_df], sort=False, ignore_index=True)\n",
    "\n",
    "    return links_df, nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sending_receiving(t, t_scale, links_dict=None, links_attr_dict=None):\n",
    "\n",
    "    t_sending_receiving_0 = time.time()\n",
    "    new_links_dict = {}\n",
    "    for l_id, l_traf in links_dict.items():\n",
    "        l_traf_run_new = []\n",
    "        l_traf_queue_new = l_traf['queue']\n",
    "        for [agent, t_enter] in l_traf['run']:\n",
    "            if t_enter < t*t_scale - links_attr_dict[l_id]['fft']:\n",
    "                l_traf_queue_new.append([agent, t_enter])\n",
    "            else:\n",
    "                l_traf_run_new.append([agent, t_enter])\n",
    "        l_traf_sending_new = links_attr_dict[l_id]['ou_c']/3600*t_scale\n",
    "        l_traf_receiving_new = links_attr_dict[l_id]['in_c']/3600*t_scale\n",
    "        l_traf_store_cap_remain = links_attr_dict[l_id]['st_c'] - len(l_traf_run_new) - len(l_traf_queue_new) ###? storage cap does not change with time slice size, but sending and receiving cap change with time slice size\n",
    "        new_links_dict[l_id] = {'run': l_traf_run_new, 'queue': l_traf_queue_new, 'send': l_traf_sending_new, 'receive': l_traf_receiving_new, 'st_remain': l_traf_store_cap_remain, 'tot_in': l_traf['tot_in'], 'tot_out': l_traf['tot_out']}\n",
    "    t_sending_receiving_1 = time.time()\n",
    "#     print('link model time {} sec'.format(t_sending_receiving_1 - t_sending_receiving_0))\n",
    "    \n",
    "    return new_links_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodal_transfer(t=0, t_scale=1, nodes_dict=None, links_dict=None, links_attr_dict=None, links_trav_time_dict=0, node2edge=None, reroute_flag=False):\n",
    "\n",
    "    node_transfer_0 = time.time()\n",
    "    arrival_list = []\n",
    "    move = 0\n",
    "    global veh_596_in\n",
    "\n",
    "    for n, in_out in nodes_dict.items():\n",
    "\n",
    "        in_links = in_out['in_links'].keys()\n",
    "        out_links = in_out['out_links']\n",
    "        x_mid = in_out['lon']\n",
    "        y_mid = in_out['lat']\n",
    "\n",
    "        in_links = [l for l in in_links if len(links_dict[l]['queue'])>0]\n",
    "        if len(in_links) == 0:\n",
    "            continue\n",
    "\n",
    "        go_link = random.choice(in_links)\n",
    "        x_start = nodes_dict[links_attr_dict[go_link]['s_i']]['lon']\n",
    "        y_start = nodes_dict[links_attr_dict[go_link]['s_i']]['lat']\n",
    "        in_vec = (x_mid-x_start, y_mid-y_start)\n",
    "        go_vehs = []\n",
    "        left_turn_vehs = False\n",
    "        incoming_lanes = int(np.floor(links_attr_dict[go_link]['ln']))\n",
    "        incoming_vehs = len(links_dict[go_link]['queue'])\n",
    "        for ln in range(min(incoming_lanes, incoming_vehs)):\n",
    "            [agent_id, link_enter_time] = links_dict[go_link]['queue'][ln]\n",
    "            try:\n",
    "                agent_next_node = [end for (start, end) in agent_info[agent_id]['route_igraph'] if start == n][0]\n",
    "                if agent_id == 349: print('plan', t, go_link, n, agent_next_node)\n",
    "            except IndexError:\n",
    "                go_vehs.append([agent_id, None, go_link, None, link_enter_time])\n",
    "                left_turn_vehs = False or left_turn_vehs\n",
    "                continue\n",
    "\n",
    "            ol = node2edge[(n, agent_next_node)]\n",
    "            go_vehs.append([agent_id, agent_next_node, go_link, ol, link_enter_time])\n",
    "            if links_attr_dict[go_link]['ty']=='v': ### virtual enter\n",
    "                left_turn_vehs = False or left_turn_vehs\n",
    "            else:\n",
    "                x_end = nodes_dict[agent_next_node]['lon']\n",
    "                y_end = nodes_dict[agent_next_node]['lat']\n",
    "                out_vec = (x_end-x_mid, y_end-y_mid)\n",
    "                dot = (in_vec[0]*out_vec[0] + in_vec[1]*out_vec[1])\n",
    "                det = (in_vec[0]*out_vec[1] - in_vec[1]*out_vec[0])\n",
    "                agent_dir = np.arctan2(det, dot)*180/np.pi \n",
    "                if agent_dir < -45:\n",
    "                    left_turn_vehs = True or left_turn_vehs\n",
    "        \n",
    "        op_go_vehs = []\n",
    "        if (not left_turn_vehs) and (links_attr_dict[go_link]['ty']=='real'):\n",
    "            op_go_link = nodes_dict[n]['in_links'][go_link]\n",
    "            \n",
    "            if op_go_link == None:\n",
    "                pass\n",
    "            else:\n",
    "                x_start = nodes_dict[links_attr_dict[go_link]['s_i']]['lon']\n",
    "                y_start = nodes_dict[links_attr_dict[go_link]['s_i']]['lat']\n",
    "                in_vec = (x_mid-x_start, y_mid-y_start)\n",
    "                op_incoming_lanes = int(np.floor(links_attr_dict[op_go_link]['ln']))\n",
    "                op_incoming_vehs = len(links_dict[op_go_link]['queue'])\n",
    "                for ln in range(min(op_incoming_lanes, op_incoming_vehs)):\n",
    "                    [agent_id, link_enter_time] = links_dict[op_go_link]['queue'][ln]\n",
    "                    try:\n",
    "                        agent_next_node = [end for (start, end) in agent_info[agent_id]['route_igraph'] if start == n][0]\n",
    "                        if agent_id == 349: print('plan_op', t, op_go_link, n, agent_next_node)\n",
    "                    except IndexError:\n",
    "                        op_go_vehs.append([agent_id, None, op_go_link, None, link_enter_time])\n",
    "                        continue\n",
    "                    ol = node2edge[(n, agent_next_node)]\n",
    "                    x_end = nodes_dict[agent_next_node]['lon']\n",
    "                    y_end = nodes_dict[agent_next_node]['lat']\n",
    "                    out_vec = (x_end-x_mid, y_end-y_mid)\n",
    "                    dot = (in_vec[0]*out_vec[0] + in_vec[1]*out_vec[1])\n",
    "                    det = (in_vec[0]*out_vec[1] - in_vec[1]*out_vec[0])\n",
    "                    agent_dir = np.arctan2(det, dot)*180/np.pi \n",
    "                    if agent_dir > 45:\n",
    "                        op_go_vehs.append([agent_id, agent_next_node, op_go_link, ol, link_enter_time])\n",
    "                    elif agent_dir > -45:\n",
    "                        op_go_vehs.append([agent_id, agent_next_node, op_go_link, ol, link_enter_time])\n",
    "                    else:\n",
    "                        pass ### no left turn allowed for opposite lane \"bonus movement\"\n",
    "                \n",
    "        for go_vehs_list in [go_vehs, op_go_vehs]:\n",
    "            for [agent_id, next_node, il, ol, link_enter_time] in go_vehs_list:\n",
    "                ### Agent reaching destination\n",
    "                if (next_node is None) and (n == agent_info[agent_id]['d_sp']-1):\n",
    "                    del agent_info[agent_id]\n",
    "                    arrival_list.append([agent_id, t])\n",
    "                    links_dict[go_link]['queue'] = [v for v in links_dict[go_link]['queue'] if v[0]!=agent_id]\n",
    "                    links_dict[go_link]['send'] = max(0, links_dict[go_link]['send']-1)\n",
    "                    links_dict[go_link]['tot_out'] += 1\n",
    "                    try:\n",
    "                        links_trav_time_dict[go_link].append((t, t*t_scale-link_enter_time))\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                    continue\n",
    "                \n",
    "                ### no storage capacity downstream\n",
    "                if links_dict[ol]['st_remain'] < 1:\n",
    "                    pass ### no blocking, as # veh = # lanes\n",
    "                ### inlink-sending, outlink-receiving both permits\n",
    "                elif (links_dict[il]['send'] >= 1) & (links_dict[ol]['receive'] >= 1):\n",
    "                    move += 1\n",
    "                    agent_info[agent_id]['cls'] = n\n",
    "                    agent_info[agent_id]['cle'] = next_node\n",
    "                    links_dict[il]['queue'] = [v for v in links_dict[il]['queue'] if v[0]!=agent_id]\n",
    "                    links_dict[il]['send'] -= 1 ### guaranted larger than 0\n",
    "                    links_dict[il]['tot_out'] += 1\n",
    "                    links_dict[ol]['run'].append((agent_id, t*t_scale))\n",
    "                    links_dict[ol]['receive'] -= 1 ### guaranted larger than \n",
    "                    links_dict[ol]['tot_in'] += 1\n",
    "                    if ol == 596: veh_596_in.append(agent_id)\n",
    "                    if agent_id == 349: print('flow', t, agent_info[agent_id]['cls'], agent_info[agent_id]['cle'])\n",
    "                    try:\n",
    "                        links_trav_time_dict[il].append((t, t*t_scale-link_enter_time))\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                else: ### either inlink-sending or outlink-receiving or both exhaust\n",
    "                    control_cap = min(links_dict[il]['send'], links_dict[ol]['receive'])\n",
    "                    toss_coin = random.choices([0,1], weights=[1-control_cap, control_cap], k=1)\n",
    "                    if toss_coin[0]:\n",
    "                        move += 1\n",
    "                        if agent_id == 349: print('chance', t, agent_info[agent_id]['cls'], agent_info[agent_id]['cle'], n, next_node)\n",
    "                        agent_info[agent_id]['cls'] = n\n",
    "                        agent_info[agent_id]['cle'] = next_node\n",
    "                        links_dict[il]['queue'] = [v for v in links_dict[il]['queue'] if v[0]!=agent_id]\n",
    "                        links_dict[il]['send'] = max(0, links_dict[il]['send']-1)\n",
    "                        links_dict[il]['tot_out'] += 1\n",
    "                        links_dict[ol]['run'].append((agent_id, t*t_scale))\n",
    "                        links_dict[ol]['receive'] = max(0, links_dict[ol]['receive']-1)\n",
    "                        links_dict[ol]['tot_in'] += 1\n",
    "                        if ol == 596: veh_596_in.append(agent_id)\n",
    "                        try:\n",
    "                            links_trav_time_dict[il].append((t, t*t_scale-link_enter_time))\n",
    "                        except KeyError:\n",
    "                            pass\n",
    "                    else:\n",
    "                        pass\n",
    "    \n",
    "#     print(t, agent_info[0])\n",
    "    node_transfer_1 = time.time()\n",
    "#     print('node model time {}'.format(node_transfer_1 - node_transfer_0))\n",
    "    \n",
    "    return links_dict, links_trav_time_dict, arrival_list, move, agent_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trips(t, t_scale, links_dict, node2edge):\n",
    "\n",
    "    for a, info in agent_info.items():\n",
    "        if (info['d_tm'] == t):\n",
    "            initial_edge = node2edge[info['route_igraph'][0]]\n",
    "            links_dict[initial_edge]['run'].append([a, t*t_scale])\n",
    "        \n",
    "    return links_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "    global g\n",
    "    global agent_info\n",
    "    \n",
    "    reroute_flag = False\n",
    "    reroute_freq = 10 ### sec\n",
    "    link_time_lookback_freq = 20 ### sec\n",
    "    counterflow_flag = False\n",
    "    closure_flag = False\n",
    "    phased_flag = False\n",
    "    scen_nm = '3_per_origin_nrr'\n",
    "    network_file_edges = '/projects/bolinas_stinson_beach/network_inputs/osm_edges.csv'\n",
    "    network_file_nodes = '/projects/bolinas_stinson_beach/network_inputs/osm_nodes.csv'\n",
    "    demand_files = ['/projects/bolinas_stinson_beach/demand_inputs/bolinas_od_3_per_origin.csv']\n",
    "    simulation_outputs = '/projects/bolinas_stinson_beach/simulation_outputs'\n",
    "\n",
    "    t_scale = 1\n",
    "\n",
    "    g, links_df0, nodes_df0 = network(\n",
    "        counterflow = counterflow_flag, \n",
    "        closure = closure_flag, \n",
    "        network_file_edges = network_file_edges,\n",
    "        network_file_nodes = network_file_nodes,\n",
    "        simulation_outputs = simulation_outputs,\n",
    "        scen_nm = scen_nm)\n",
    "    # return\n",
    "    od = demand(nodes_df0, \n",
    "        phased_flag = phased_flag,\n",
    "        demand_files = demand_files)\n",
    "    \n",
    "    links_df, nodes_df = virtual_nodes_links(links_df0, nodes_df0)\n",
    "    print(links_df.shape, nodes_df.shape, links_df0.shape, nodes_df0.shape)\n",
    "    \n",
    "    node2edge = {(getattr(e, 'start_igraph'), getattr(e, 'end_igraph')): getattr(e, 'edge_id_igraph') for e in links_df.itertuples()}\n",
    "\n",
    "    links_attr_dict = {getattr(e, 'edge_id_igraph'): {'fft': getattr(e, 'fft'), 'len': getattr(e, 'length'), 'ty': getattr(e, 'stype'), 'ln': getattr(e, 'lanes'), 's_i': getattr(e, 'start_igraph'), 'e_i': getattr(e, 'end_igraph'), 'geom': getattr(e, 'geometry'), 'in_c': getattr(e, 'capacity'), 'ou_c': getattr(e, 'capacity'), 'st_c': getattr(e, 'store_cap')} for e in links_df.itertuples()}\n",
    "\n",
    "    ### signal at entrance to chico\n",
    "    # links_attr_dict[21044]['ou_c'] /= 2\n",
    "    links_dict = {e: {'run': [], 'queue': [], 'tot_in': 0, 'tot_out': 0} for e in links_df['edge_id_igraph'].values.tolist()}\n",
    "    links_trav_time_dict = {e: [] for e in links_df.loc[links_df['stype']=='real', 'edge_id_igraph'].values.tolist()}\n",
    "    global veh_596_in\n",
    "    veh_596_in = []\n",
    "\n",
    "    nodes_dict = {getattr(n, 'node_id_igraph'): {'in_links': {}, 'out_links': [], 'lon': getattr(n, 'lon'), 'lat': getattr(n, 'lat')} for n in nodes_df.itertuples()}\n",
    "    for l in links_df.itertuples():\n",
    "        nodes_dict[getattr(l, 'start_igraph')]['out_links'].append(getattr(l, 'edge_id_igraph'))\n",
    "        nodes_dict[getattr(l, 'end_igraph')]['in_links'][getattr(l, 'edge_id_igraph')] = None\n",
    "    for n, in_out in nodes_dict.items():\n",
    "        x_mid = in_out['lon']\n",
    "        y_mid = in_out['lat']\n",
    "        for il in in_out['in_links'].keys():\n",
    "            x_start = nodes_dict[links_attr_dict[il]['s_i']]['lon']\n",
    "            y_start = nodes_dict[links_attr_dict[il]['s_i']]['lat']\n",
    "            in_vec = (x_mid-x_start, y_mid-y_start)\n",
    "            sa_ol = None ### straight ahead out link\n",
    "            ol_dir = 180\n",
    "            for ol in in_out['out_links']:\n",
    "                x_end = nodes_dict[links_attr_dict[ol]['e_i']]['lon']\n",
    "                y_end = nodes_dict[links_attr_dict[ol]['e_i']]['lat']\n",
    "                out_vec = (x_end-x_mid, y_end-y_mid)\n",
    "                dot = (in_vec[0]*out_vec[0] + in_vec[1]*out_vec[1])\n",
    "                det = (in_vec[0]*out_vec[1] - in_vec[1]*out_vec[0])\n",
    "                new_ol_dir = np.arctan2(det, dot)*180/np.pi\n",
    "                if abs(new_ol_dir)<ol_dir:\n",
    "                    sa_ol = ol\n",
    "                    ol_dir = new_ol_dir\n",
    "            if (abs(ol_dir)<=45) and links_attr_dict[il]['ty']=='real':\n",
    "                nodes_dict[n]['in_links'][il] = sa_ol\n",
    "\n",
    "    total_arrival_count = 0\n",
    "    total_arrival_list = []\n",
    "    agent_info = {}\n",
    "    track_edges = [295, 543, 596]\n",
    "    track_edge_info = []\n",
    "    \n",
    "    t_s = 0\n",
    "    t_e = 1500\n",
    "    for t in range(t_s, t_e):\n",
    "        ### calculate the paths for agents moving in the next 60 seconds\n",
    "        if (t==0) or (reroute_flag) and (t%reroute_freq == 0):\n",
    "            ### add new agents that are scheduled to leave in the next reroute period\n",
    "            ### to the remaining agents\n",
    "            new_od = od.loc[(od['d_tm']>=t//reroute_freq*reroute_freq) & (od['d_tm']<(t//reroute_freq+1)*reroute_freq)]\n",
    "            for row in new_od.itertuples():\n",
    "                agent_info[getattr(row, 'agent_id')] = {'o_sp': getattr(row, 'o_sp'), 'd_sp': getattr(row, 'd_sp'), 'd_tm': getattr(row, 'd_tm'), 'cls': getattr(row, 'cls'), 'cle': getattr(row, 'cle')}\n",
    "            # print('{} reroutes at time {}, {} newly added'.format(len(agent_info), t, new_od.shape[0]))\n",
    "            ### update link travel time\n",
    "            links_trav_time_dict = update_graph(links_attr_dict = links_attr_dict, links_trav_time_dict=links_trav_time_dict, link_time_lookback_freq = link_time_lookback_freq)\n",
    "            ### route\n",
    "            agent_info = route(links_df0, counterflow=counterflow_flag, simulation_outputs = simulation_outputs, scen_nm = scen_nm)\n",
    "        if t==0: print(agent_info[349])\n",
    "\n",
    "        ### load trips onto the network\n",
    "        links_dict = load_trips(t, t_scale, links_dict, node2edge)\n",
    "        ### link model\n",
    "        links_dict = sending_receiving(t, t_scale, links_dict=links_dict, links_attr_dict=links_attr_dict)\n",
    "        # output_interpolated_positions(t=t, links_dict=links_dict, links_attr_dict=links_attr_dict, simulation_outputs=simulation_outputs)\n",
    "        ### node model\n",
    "        links_dict, links_trav_time_dict, arrival_list, move, agent_info = nodal_transfer(t=t, t_scale=t_scale, nodes_dict=nodes_dict, links_dict=links_dict, links_attr_dict=links_attr_dict, links_trav_time_dict=links_trav_time_dict, node2edge=node2edge, reroute_flag=reroute_flag,)\n",
    "        total_arrival_count += len(arrival_list)\n",
    "        queue_veh = sum([len(l['queue']) for l in links_dict.values()])\n",
    "        queue_link = len([l for l in links_dict.values() if len(l['queue'])>0])\n",
    "        run_link = len([l for l in links_dict.values() if len(l['run'])>0])\n",
    "        total_arrival_list.append([t, total_arrival_count, move, queue_veh, queue_link, run_link])\n",
    "\n",
    "        if t%500==0:\n",
    "            print(total_arrival_list[-1])\n",
    "            pd.DataFrame([[l, len(v['run']), len(v['queue']), links_attr_dict[l]['geom']] for l, v in links_dict.items()], columns=['edge_id_igraph', 'run', 'queue', 'geom']).to_csv(absolute_path+simulation_outputs+'/run_queue/run_queue_{}_{}s.csv'.format(scen_nm, t), index=False)\n",
    "        \n",
    "        ### occupancy of selected edges\n",
    "        for t_edge in track_edges:\n",
    "            track_edge_info.append([t, t_edge, len(links_dict[t_edge]['run']), len(links_dict[t_edge]['queue']), links_dict[t_edge]['tot_in'], links_dict[t_edge]['tot_out']])\n",
    "\n",
    "\n",
    "    pd.DataFrame(total_arrival_list, columns=['t_sec', 'tot_arr', 'move', 'q_veh', 'q_l', 'r_l']).to_csv(absolute_path+simulation_outputs+'/arrival_counts/arrival_counts_{}_{}s_{}s.csv'.format(scen_nm, t_s, t_e), index=False)\n",
    "    pd.DataFrame(track_edge_info, columns=['t_sec', 'edge_id_igraph', 'run', 'queue', 'tot_in', 'tot_out']).to_csv(absolute_path+simulation_outputs+'/arrival_counts/track_edges_{}_{}s_{}s.csv'.format(scen_nm, t_s, t_e), index=False)\n",
    "    print(len(veh_596_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_interpolated_positions(t=0, links_dict=None, links_attr_dict=None, simulation_outputs=None):\n",
    "    \n",
    "    output_interpolated_0 = time.time()\n",
    "    veh_loc = []\n",
    "    for l_id, l in links_dict.items():\n",
    "        if links_attr_dict[l_id]['ty'] == 'v':\n",
    "            continue\n",
    "        l_len = links_attr_dict[l_id]['len']\n",
    "        l_ln = links_attr_dict[l_id]['ln']\n",
    "        l_fft = links_attr_dict[l_id]['fft']\n",
    "        l_geom = loads(links_attr_dict[l_id]['geom'])\n",
    "        q_v_loc = l_len\n",
    "        q_v_loc_count = 0\n",
    "        run_veh = sorted(l['run'],key=itemgetter(1))\n",
    "        queue_veh = sorted(l['queue'],key=itemgetter(1))\n",
    "        for q_v in queue_veh:\n",
    "            q_v_loc = max(min(q_v_loc*(1), l_len), 0)\n",
    "            q_v_coord = l_geom.interpolate(q_v_loc/l_len, normalized=True)\n",
    "            veh_loc.append([t, l_id, q_v[0], 'q', q_v_coord.x, q_v_coord.y])\n",
    "            q_v_loc_count += 1\n",
    "            if q_v_loc_count == l_ln:\n",
    "                q_v_loc -= 8\n",
    "                q_v_loc_count = 0\n",
    "        queue_loc = q_v_loc\n",
    "        for r_v in run_veh:\n",
    "            if l_len*(t-r_v[1])/l_fft>queue_loc:\n",
    "                r_v_loc = queue_loc\n",
    "                q_v_loc_count += 1\n",
    "                if q_v_loc_count == l_ln:\n",
    "                    q_v_loc -= 8\n",
    "                    q_v_loc_count = 0\n",
    "            else:\n",
    "                r_v_loc = l_len*(t-r_v[1])/l_fft\n",
    "            r_v_loc = max(min(r_v_loc*(1), l_len), 0)\n",
    "            r_v_coord = l_geom.interpolate(r_v_loc/l_len, normalized=True)\n",
    "            veh_loc.append([t, l_id, r_v[0], 'r', r_v_coord.x, r_v_coord.y])\n",
    "    \n",
    "    pd.DataFrame(veh_loc, columns=['t_sec', 'l_id', 'v_id', 'status', 'lon', 'lat']).to_csv(absolute_path + simulation_outputs + '/veh_loc/veh_loc_{}s.csv'.format(t), index=False)\n",
    "    output_interpolated_1 = time.time()\n",
    "#     print('output interpolated {} sec'.format(output_interpolated_1 - output_interpolated_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(256, 256) 605\ntotal numbers of agents from file  (519, 6)\ntotal numbers of agents taken  (519, 6)\n   agent_id  o_sp  d_sp  d_tm    cls  cle\n0       421   209   187     0  vn208  208\n1       107    45   156     0   vn44   44\n2       310   141   187     0  vn140  140\n3       233   110   187     0  vn109  109\n4       173    86   187     0   vn85   85\n(861, 11) (512, 6) (605, 11) (256, 6)\n{'o_sp': 157, 'd_sp': 187, 'd_tm': 0, 'cls': 'vn156', 'cle': 156, 'route_igraph': [('vn156', 156), (156, 17), (17, 11), (11, 7), (7, 135), (135, 61), (61, 134), (134, 202), (202, 20), (20, 22), (22, 183), (183, 248), (248, 197), (197, 6), (6, 186)]}\n[0, 0, 0, 0, 0, 173]\nplan 1 n156_vl 156 17\nplan 2 n156_vl 156 17\nchance 2 vn156 156 156 17\nplan 18 319 17 11\nplan 19 319 17 11\nplan 22 319 17 11\nchance 22 156 17 17 11\nplan 40 202 11 7\nchance 40 17 11 11 7\nplan 75 200 7 135\nchance 75 11 7 7 135\nplan_op 101 411 7 135\nplan 101 411 135 61\nchance 101 7 135 135 61\nplan 103 566 61 134\nplan_op 103 566 135 61\nplan 104 566 61 134\nchance 104 135 61 61 134\nplan 113 564 134 202\nplan_op 114 564 61 134\nplan 114 564 134 202\nchance 114 61 134 134 202\nplan 126 562 202 20\nplan 127 562 202 20\nplan_op 128 562 134 202\nplan 128 562 202 20\nplan 129 562 202 20\nplan 130 562 202 20\nplan 131 562 202 20\nplan 132 562 202 20\nplan 133 562 202 20\nplan 134 562 202 20\nplan_op 135 562 134 202\nchance 135 134 202 134 202\nplan_op 159 562 134 202\nplan 159 562 202 20\nchance 159 134 202 202 20\nplan 251 602 20 22\nplan 254 602 20 22\nplan 255 602 20 22\nplan 262 602 20 22\nplan 264 602 20 22\nplan 265 602 20 22\nchance 265 202 20 20 22\nplan 329 600 22 183\nplan_op 330 600 20 22\nplan 330 600 22 183\nplan 331 600 22 183\nplan 332 600 22 183\nplan_op 333 600 20 22\nplan 333 600 22 183\nchance 333 20 22 22 183\nplan_op 378 598 22 183\nplan 378 598 183 248\nchance 378 22 183 183 248\n[500, 3, 9, 229, 17, 23]\nplan 545 596 248 197\nplan_op 546 596 183 248\nchance 546 183 248 183 248\nplan_op 719 596 183 248\nplan 719 596 248 197\nplan_op 720 596 183 248\nplan 720 596 248 197\nchance 720 183 248 248 197\nplan 736 520 197 6\nchance 736 248 197 197 6\nplan 762 549 6 186\nchance 762 197 6 6 186\nplan_op 996 551 6 186\n[1000, 89, 8, 104, 5, 14]\n789\n"
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geo)",
   "language": "python",
   "name": "geo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}